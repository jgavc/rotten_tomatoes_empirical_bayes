---
title: "Modeling Functions"
format: html
editor: visual
---

# A collection of functions used in fitting mixed betas

```{r}
# --- Beta-Binomial log pmf (stable) ---
log_beta_binom_pmf <- function(k, n, a, b) {
  # log[ choose(n,k) * Beta(k+a, n-k+b) / Beta(a,b) ]
  lchoose(n, k) +
    lbeta(k + a, n - k + b) -
    lbeta(a, b)
}

# --- Weighted negative log-likelihood for one component ---
neg_wll_component <- function(par_log, k, n, w) {
  a <- exp(par_log[1])
  b <- exp(par_log[2])
  # weighted log-likelihood
  ll <- sum(w * log_beta_binom_pmf(k, n, a, b))
  -ll
}

# --- Helper: initialize alpha/beta from mean/var of p = k/n ---
mom_beta_ab <- function(p, w = NULL) {
  if (is.null(w)) w <- rep(1, length(p))
  w <- w / sum(w)
  m <- sum(w * p)
  v <- sum(w * (p - m)^2)

  # If variance is tiny / degenerate, set large concentration
  if (!is.finite(v) || v < 1e-6) {
    phi <- 200
    return(c(alpha = max(1e-3, m * phi),
             beta  = max(1e-3, (1 - m) * phi)))
  }

  # Method of moments: v = m(1-m)/(phi+1)
  phi <- m * (1 - m) / v - 1
  if (!is.finite(phi) || phi <= 0) phi <- 10

  c(alpha = max(1e-3, m * phi),
    beta  = max(1e-3, (1 - m) * phi))
}

# --- Main EM routine ---
fit_beta_binom_mixture <- function(k, n, K = 2, max_iter = 200, tol = 1e-6,
                                   verbose = TRUE, seed = 1) {
  stopifnot(K == 2)
  k <- as.integer(k)
  n <- as.integer(n)

  ok <- is.finite(k) & is.finite(n) & n > 0 & k >= 0 & k <= n
  k <- k[ok]; n <- n[ok]
  p <- k / n

  set.seed(seed)
  # init: kmeans on proportions
  km <- kmeans(p, centers = 2)
  z <- km$cluster

  ab1 <- mom_beta_ab(p[z == 1])
  ab2 <- mom_beta_ab(p[z == 2])
  pi1 <- mean(z == 1)
  pi2 <- 1 - pi1

  a1 <- ab1["alpha"]; b1 <- ab1["beta"]
  a2 <- ab2["alpha"]; b2 <- ab2["beta"]

  loglik_prev <- -Inf

  for (iter in 1:max_iter) {

    # E-step: responsibilities
    ll1 <- log(pi1) + log_beta_binom_pmf(k, n, a1, b1)
    ll2 <- log(pi2) + log_beta_binom_pmf(k, n, a2, b2)

    # log-sum-exp
    mll <- pmax(ll1, ll2)
    denom <- mll + log(exp(ll1 - mll) + exp(ll2 - mll))

    r1 <- exp(ll1 - denom)  # responsibility for component 1
    r2 <- 1 - r1

    loglik <- sum(denom)

    # check convergence
    if (verbose && (iter %% 5 == 0 || iter == 1)) {
      cat(sprintf("iter %3d | logLik %.3f | pi1 %.3f | (a1,b1)=(%.2f,%.2f) | (a2,b2)=(%.2f,%.2f)\n",
                  iter, loglik, pi1, a1, b1, a2, b2))
    }

    if (abs(loglik - loglik_prev) < tol) break
    loglik_prev <- loglik

    # M-step: update mixing weights
    pi1 <- mean(r1)
    pi2 <- 1 - pi1

    # M-step: update (a,b) for each component via weighted MLE
    opt1 <- optim(par = log(c(a1, b1)),
                  fn = neg_wll_component,
                  k = k, n = n, w = r1,
                  method = "BFGS")
    a1 <- exp(opt1$par[1]); b1 <- exp(opt1$par[2])

    opt2 <- optim(par = log(c(a2, b2)),
                  fn = neg_wll_component,
                  k = k, n = n, w = r2,
                  method = "BFGS")
    a2 <- exp(opt2$par[1]); b2 <- exp(opt2$par[2])

    # guardrails
    a1 <- max(a1, 1e-6); b1 <- max(b1, 1e-6)
    a2 <- max(a2, 1e-6); b2 <- max(b2, 1e-6)
    pi1 <- min(max(pi1, 1e-6), 1 - 1e-6)
    pi2 <- 1 - pi1
  }

  list(
    K = 2,
    pi = c(pi1, pi2),
    alpha = c(a1, a2),
    beta  = c(b1, b2),
    logLik = loglik_prev,
    responsibilities = cbind(r1 = r1, r2 = r2),
    used_rows = which(ok),
    iterations = iter
  )
}
mix_beta_density <- function(x, pi, alpha, beta) {
  pi[1] * dbeta(x, alpha[1], beta[1]) + pi[2] * dbeta(x, alpha[2], beta[2])
}
posterior_params_mixture <- function(y, n, pi, alpha, beta) {
  K <- length(pi)

  # log unnormalized weights: log pi_k + log Beta-Binomial marginal
  ll <- log(pi) +
    lchoose(n, y) +
    lbeta(y + alpha, n - y + beta) -
    lbeta(alpha, beta)

  # stabilize and normalize
  w <- exp(ll - max(ll))
  w <- w / sum(w)

  # posterior component parameters
  post_alpha <- alpha + y
  post_beta  <- beta + (n - y)

  list(w = w, post_alpha = post_alpha, post_beta = post_beta)
}
sample_from_stored_posterior <- function(w1, a1, b1, a2, b2, S = 2000) {
  z <- rbinom(S, size = 1, prob = w1) # 1 => component 1
  # if z==1 sample from (a1,b1), else (a2,b2)
  out <- numeric(S)
  idx1 <- which(z == 1)
  idx2 <- which(z == 0)
  if (length(idx1)) out[idx1] <- rbeta(length(idx1), a1, b1)
  if (length(idx2)) out[idx2] <- rbeta(length(idx2), a2, b2)
  out
}
```

```{r}
saveRDS(object = list(fit_beta_binom_mixture = fit_beta_binom_mixture,
                      log_beta_binom_pmf = log_beta_binom_pmf,
                      mix_beta_density = mix_beta_density,
                      mom_beta_ab = mom_beta_ab,
                      neg_wll_component = neg_wll_component,
                      posterior_params_mixture = posterior_params_mixture,
                      sample_from_stored_posterior = sample_from_stored_posterior),
        file = "D:/Portfolio Projects/rotten_tomatoes_empirical_bayes/Data/Functions/fit_mixed_beta_helpers.RData")
```
